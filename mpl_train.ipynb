{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "607c5d75-63e9-41ee-a67e-dc40f404ccd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T07:26:47.972244Z",
     "iopub.status.busy": "2024-03-02T07:26:47.971824Z",
     "iopub.status.idle": "2024-03-02T07:26:48.155791Z",
     "shell.execute_reply": "2024-03-02T07:26:48.155211Z",
     "shell.execute_reply.started": "2024-03-02T07:26:47.972193Z"
    },
    "jupyter": {
     "source_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa474b3",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75f7a5cc-c00e-44f0-a433-fbdd04edd5be",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-03-02T07:26:49.098508Z",
     "iopub.status.busy": "2024-03-02T07:26:49.098058Z",
     "iopub.status.idle": "2024-03-02T07:26:51.638710Z",
     "shell.execute_reply": "2024-03-02T07:26:51.638160Z",
     "shell.execute_reply.started": "2024-03-02T07:26:49.098468Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_text_encode = pd.read_csv(\"./bert/sample_text_encode.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "073ba99e-b7ad-4457-9041-62c4f9b168e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T07:26:55.384489Z",
     "iopub.status.busy": "2024-03-02T07:26:55.384236Z",
     "iopub.status.idle": "2024-03-02T07:26:55.393566Z",
     "shell.execute_reply": "2024-03-02T07:26:55.393178Z",
     "shell.execute_reply.started": "2024-03-02T07:26:55.384467Z"
    },
    "jupyter": {
     "source_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20211"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "with open('./bert/train_label.csv', encoding = 'utf-8-sig') as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if line == \"\":\n",
    "            break\n",
    "        line = line.strip('\\n')\n",
    "        labels.append(line)\n",
    "f.close\n",
    "labels = labels[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7fc7789-e50f-477d-9a5b-3512250f22a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T07:26:56.677521Z",
     "iopub.status.busy": "2024-03-02T07:26:56.677294Z",
     "iopub.status.idle": "2024-03-02T07:26:56.707160Z",
     "shell.execute_reply": "2024-03-02T07:26:56.706223Z",
     "shell.execute_reply.started": "2024-03-02T07:26:56.677499Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [int(i) for i in labels]\n",
    "y = np.array(labels)\n",
    "x = np.array(sample_text_encode)\n",
    "\n",
    "del sample_text_encode, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e2ca0d2-f2a1-48c6-9397-e9ca9c387259",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T07:26:58.416970Z",
     "iopub.status.busy": "2024-03-02T07:26:58.416632Z",
     "iopub.status.idle": "2024-03-02T07:26:58.528287Z",
     "shell.execute_reply": "2024-03-02T07:26:58.527478Z",
     "shell.execute_reply.started": "2024-03-02T07:26:58.416935Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = len(y)\n",
    "import random\n",
    "index = random.sample(range(n),n)\n",
    "index_test = index[:1000]\n",
    "index_train = index[1000:]\n",
    "x_train = x[index_train]\n",
    "y_train = y[index_train]\n",
    "x_test = x[index_test]\n",
    "y_test = y[index_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1fedb4-ac00-48d9-9ead-c15e39bb93e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a116eb41-ce62-4bfe-a797-7d3625407568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T07:27:06.022003Z",
     "iopub.status.busy": "2024-03-02T07:27:06.021621Z",
     "iopub.status.idle": "2024-03-02T07:27:06.102950Z",
     "shell.execute_reply": "2024-03-02T07:27:06.102337Z",
     "shell.execute_reply.started": "2024-03-02T07:27:06.021963Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 转换为PyTorch张量\n",
    "import torch\n",
    "X_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_train, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a01e63f4-573a-46b3-b1d6-982d7f421823",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T07:27:11.217638Z",
     "iopub.status.busy": "2024-03-02T07:27:11.217344Z",
     "iopub.status.idle": "2024-03-02T07:27:11.269826Z",
     "shell.execute_reply": "2024-03-02T07:27:11.269256Z",
     "shell.execute_reply.started": "2024-03-02T07:27:11.217614Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 分割数据集为训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=64) \n",
    "\n",
    "# 创建训练和验证的数据加载器\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be69099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y1_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bdf4db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset1 = TensorDataset(X1_tensor, y1_tensor)\n",
    "val_loader1 = DataLoader(val_dataset1, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42137b94",
   "metadata": {},
   "source": [
    "## 训练神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0848b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_sizes, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        # 初始化权重\n",
    "        self.initializer = nn.init.KaimingNormal()\n",
    "        \n",
    "        # 第一个隐藏层\n",
    "        self.layers = [nn.Linear(input_size, hidden_layer_sizes[0]), nn.ReLU()]\n",
    "        # 添加更多的隐藏层\n",
    "        for i in range(1, len(hidden_layer_sizes)):\n",
    "            self.layers.extend([\n",
    "                nn.Linear(hidden_layer_sizes[i-1], hidden_layer_sizes[i]),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(hidden_layer_sizes[i])\n",
    "            ])\n",
    "        # 最后一个隐藏层到输出层\n",
    "        self.layers.append(nn.Linear(hidden_layer_sizes[-1], output_size))\n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                self.initializer(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0c80868-414f-427d-9558-58551d89e002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T08:21:53.904191Z",
     "iopub.status.busy": "2024-03-02T08:21:53.903859Z",
     "iopub.status.idle": "2024-03-02T08:21:53.911017Z",
     "shell.execute_reply": "2024-03-02T08:21:53.910592Z",
     "shell.execute_reply.started": "2024-03-02T08:21:53.904169Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建优化函数\n",
    "def optimize(trial):\n",
    "    # 定义超参数搜索空间\n",
    "    input_size = 768  # 假设的输入特征大小\n",
    "    hidden_layer_sizes = [trial.suggest_int('h1', 10, 200),\n",
    "                         trial.suggest_int('h2', 10, 200),\n",
    "                         trial.suggest_int('h3', 10, 200)]\n",
    "    output_size = 2  # 类别数\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD'])\n",
    "    batch_size = trial.suggest_int('batch_size', 32, 256, step=32)\n",
    "\n",
    "    # 创建模型\n",
    "    model = MLP(input_size, hidden_layer_sizes, output_size)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    # model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # 创建优化器\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 训练模型\n",
    "    # 训练时，设置模型为训练模式\n",
    "    model.train()\n",
    "    for epoch in range(10):  # 假设训练10个epoch\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data.to(device))\n",
    "            loss = nn.CrossEntropyLoss()(output, target.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # 评估模型\n",
    "    model.eval()\n",
    "    # 在评估循环中，模型不会应用Dropout\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            predictions = model(data.to(device)).argmax(dim=1)\n",
    "            total_correct += (predictions == target.to(device)).sum().item()\n",
    "            total_samples += target.size(0)\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    # 返回验证集上的准确率\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6506b70e-40f6-4557-b3f7-f554bbd83151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install cmaes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "105b6eac-720c-4a77-8b62-a7d8e179386c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T08:21:57.000540Z",
     "iopub.status.busy": "2024-03-02T08:21:57.000098Z",
     "iopub.status.idle": "2024-03-02T08:27:27.010605Z",
     "shell.execute_reply": "2024-03-02T08:27:27.009812Z",
     "shell.execute_reply.started": "2024-03-02T08:21:57.000499Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-03-02 08:21:57,002] A new study created in memory with name: no-name-2399bb08-a58e-490a-84b3-3ac01d476a43\n",
      "[I 2024-03-02 08:21:59,798] Trial 0 finished with value: 0.5572594607964383 and parameters: {'h1': 694, 'h2': 434, 'h3': 109, 'dropout_rate': 0.25906861233345113, 'learning_rate': 0.00019616184780627278, 'optimizer': 'SGD', 'batch_size': 256}. Best is trial 0 with value: 0.5572594607964383.\n",
      "[I 2024-03-02 08:22:03,077] Trial 1 finished with value: 0.8206777145683898 and parameters: {'h1': 721, 'h2': 409, 'h3': 215, 'dropout_rate': 0.026879509610615693, 'learning_rate': 0.0002847470474272649, 'optimizer': 'Adam', 'batch_size': 128}. Best is trial 1 with value: 0.8206777145683898.\n",
      "[I 2024-03-02 08:22:06,285] Trial 2 finished with value: 0.8083106604006925 and parameters: {'h1': 752, 'h2': 346, 'h3': 259, 'dropout_rate': 0.28131795956310746, 'learning_rate': 0.0021159682449778294, 'optimizer': 'Adam', 'batch_size': 160}. Best is trial 1 with value: 0.8206777145683898.\n",
      "[I 2024-03-02 08:22:09,098] Trial 3 finished with value: 0.7830818698985902 and parameters: {'h1': 675, 'h2': 359, 'h3': 396, 'dropout_rate': 0.22558980749116314, 'learning_rate': 0.013305657801873332, 'optimizer': 'SGD', 'batch_size': 64}. Best is trial 1 with value: 0.8206777145683898.\n",
      "[I 2024-03-02 08:22:11,936] Trial 4 finished with value: 0.8144941874845412 and parameters: {'h1': 766, 'h2': 384, 'h3': 361, 'dropout_rate': 0.1470988862710274, 'learning_rate': 0.019966769590960085, 'optimizer': 'SGD', 'batch_size': 192}. Best is trial 1 with value: 0.8206777145683898.\n",
      "[I 2024-03-02 08:22:14,777] Trial 5 finished with value: 0.5572594607964383 and parameters: {'h1': 789, 'h2': 363, 'h3': 352, 'dropout_rate': 0.12424462452577373, 'learning_rate': 0.0002414477283433084, 'optimizer': 'SGD', 'batch_size': 256}. Best is trial 1 with value: 0.8206777145683898.\n",
      "[I 2024-03-02 08:22:17,568] Trial 6 finished with value: 0.8172149394014345 and parameters: {'h1': 718, 'h2': 360, 'h3': 341, 'dropout_rate': 0.32904584460621367, 'learning_rate': 0.05012902771396398, 'optimizer': 'SGD', 'batch_size': 192}. Best is trial 1 with value: 0.8206777145683898.\n",
      "[I 2024-03-02 08:22:20,393] Trial 7 finished with value: 0.4427405392035617 and parameters: {'h1': 748, 'h2': 338, 'h3': 147, 'dropout_rate': 0.46714617654338747, 'learning_rate': 1.3044518328372659e-05, 'optimizer': 'SGD', 'batch_size': 128}. Best is trial 1 with value: 0.8206777145683898.\n",
      "[I 2024-03-02 08:22:23,242] Trial 8 finished with value: 0.8055899084837992 and parameters: {'h1': 762, 'h2': 308, 'h3': 128, 'dropout_rate': 0.4216049170112567, 'learning_rate': 0.007309810843920645, 'optimizer': 'SGD', 'batch_size': 224}. Best is trial 1 with value: 0.8206777145683898.\n",
      "[I 2024-03-02 08:22:26,159] Trial 9 finished with value: 0.7731882265644323 and parameters: {'h1': 797, 'h2': 487, 'h3': 493, 'dropout_rate': 0.45360427785285357, 'learning_rate': 0.010190493588653548, 'optimizer': 'SGD', 'batch_size': 224}. Best is trial 1 with value: 0.8206777145683898.\n",
      "[I 2024-03-02 08:22:29,450] Trial 10 finished with value: 0.8144941874845412 and parameters: {'h1': 611, 'h2': 425, 'h3': 224, 'dropout_rate': 0.00798609809346771, 'learning_rate': 1.340892700572009e-05, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 1 with value: 0.8206777145683898.\n",
      "[I 2024-03-02 08:22:32,749] Trial 11 finished with value: 0.4427405392035617 and parameters: {'h1': 720, 'h2': 418, 'h3': 212, 'dropout_rate': 0.34445337065108894, 'learning_rate': 0.06913256669979263, 'optimizer': 'Adam', 'batch_size': 128}. Best is trial 1 with value: 0.8206777145683898.\n",
      "[I 2024-03-02 08:22:36,042] Trial 12 finished with value: 0.8204303734850359 and parameters: {'h1': 654, 'h2': 461, 'h3': 310, 'dropout_rate': 0.016478262258617864, 'learning_rate': 0.0003764643421142879, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 1 with value: 0.8206777145683898.\n",
      "[I 2024-03-02 08:22:39,329] Trial 13 finished with value: 0.8186989859015582 and parameters: {'h1': 653, 'h2': 476, 'h3': 287, 'dropout_rate': 0.00611169390568685, 'learning_rate': 0.00022596421689019273, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 1 with value: 0.8206777145683898.\n",
      "[I 2024-03-02 08:22:42,604] Trial 14 finished with value: 0.824387830818699 and parameters: {'h1': 636, 'h2': 455, 'h3': 192, 'dropout_rate': 0.08461034732124034, 'learning_rate': 0.0006498616994705073, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 14 with value: 0.824387830818699.\n",
      "[I 2024-03-02 08:22:45,859] Trial 15 finished with value: 0.824387830818699 and parameters: {'h1': 600, 'h2': 455, 'h3': 194, 'dropout_rate': 0.09532472606713085, 'learning_rate': 5.8406712572999314e-05, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 14 with value: 0.824387830818699.\n",
      "[I 2024-03-02 08:22:49,093] Trial 16 finished with value: 0.8246351719020529 and parameters: {'h1': 605, 'h2': 453, 'h3': 166, 'dropout_rate': 0.10292119533769911, 'learning_rate': 5.9407971267343e-05, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 16 with value: 0.8246351719020529.\n",
      "[I 2024-03-02 08:22:52,360] Trial 17 finished with value: 0.8174622804847885 and parameters: {'h1': 630, 'h2': 445, 'h3': 172, 'dropout_rate': 0.1754067044285247, 'learning_rate': 0.001769747567337304, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 16 with value: 0.8246351719020529.\n",
      "[I 2024-03-02 08:22:55,746] Trial 18 finished with value: 0.8177096215681424 and parameters: {'h1': 629, 'h2': 492, 'h3': 159, 'dropout_rate': 0.08466100146252427, 'learning_rate': 6.290913349716866e-05, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 16 with value: 0.8246351719020529.\n",
      "[I 2024-03-02 08:22:59,783] Trial 19 finished with value: 0.8221617610685135 and parameters: {'h1': 629, 'h2': 388, 'h3': 268, 'dropout_rate': 0.1859550601890852, 'learning_rate': 5.806071468892704e-05, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 16 with value: 0.8246351719020529.\n",
      "[I 2024-03-02 08:23:03,805] Trial 20 finished with value: 0.810784071234232 and parameters: {'h1': 658, 'h2': 459, 'h3': 103, 'dropout_rate': 0.07429703401837859, 'learning_rate': 0.0009181073000349305, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 16 with value: 0.8246351719020529.\n",
      "[I 2024-03-02 08:23:07,938] Trial 21 finished with value: 0.819935691318328 and parameters: {'h1': 607, 'h2': 451, 'h3': 181, 'dropout_rate': 0.096271521531457, 'learning_rate': 4.232298349321615e-05, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 16 with value: 0.8246351719020529.\n",
      "[I 2024-03-02 08:23:12,093] Trial 22 finished with value: 0.8229037843185754 and parameters: {'h1': 605, 'h2': 476, 'h3': 191, 'dropout_rate': 0.0747844895798673, 'learning_rate': 2.956730550997178e-05, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 16 with value: 0.8246351719020529.\n",
      "[I 2024-03-02 08:23:16,215] Trial 23 finished with value: 0.8075686371506308 and parameters: {'h1': 624, 'h2': 434, 'h3': 244, 'dropout_rate': 0.13643278921495694, 'learning_rate': 0.00012645559713804301, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 16 with value: 0.8246351719020529.\n",
      "[I 2024-03-02 08:23:20,297] Trial 24 finished with value: 0.7996537224833045 and parameters: {'h1': 600, 'h2': 467, 'h3': 151, 'dropout_rate': 0.05776750226572284, 'learning_rate': 0.0007071852611994231, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 16 with value: 0.8246351719020529.\n",
      "[I 2024-03-02 08:23:23,807] Trial 25 finished with value: 0.8266139005688845 and parameters: {'h1': 640, 'h2': 438, 'h3': 197, 'dropout_rate': 0.2053393204782712, 'learning_rate': 0.00011063786516125231, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 25 with value: 0.8266139005688845.\n",
      "[I 2024-03-02 08:23:27,112] Trial 26 finished with value: 0.8271085827355924 and parameters: {'h1': 644, 'h2': 403, 'h3': 242, 'dropout_rate': 0.19205146771707937, 'learning_rate': 0.003464768817208727, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:23:30,383] Trial 27 finished with value: 0.8038585209003215 and parameters: {'h1': 671, 'h2': 397, 'h3': 233, 'dropout_rate': 0.21030476232731382, 'learning_rate': 0.00427114346331397, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:23:33,696] Trial 28 finished with value: 0.8216670789018056 and parameters: {'h1': 647, 'h2': 409, 'h3': 287, 'dropout_rate': 0.30993892662133127, 'learning_rate': 9.956473423064685e-05, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:23:36,999] Trial 29 finished with value: 0.8226564432352214 and parameters: {'h1': 690, 'h2': 439, 'h3': 443, 'dropout_rate': 0.27349914468426384, 'learning_rate': 0.003090490970112095, 'optimizer': 'Adam', 'batch_size': 160}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:23:40,294] Trial 30 finished with value: 0.8135048231511254 and parameters: {'h1': 683, 'h2': 427, 'h3': 130, 'dropout_rate': 0.21696303531476135, 'learning_rate': 2.0260283058971345e-05, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:23:43,619] Trial 31 finished with value: 0.8026218154835518 and parameters: {'h1': 640, 'h2': 441, 'h3': 200, 'dropout_rate': 0.16836425188045193, 'learning_rate': 0.0004468262120363715, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:23:46,928] Trial 32 finished with value: 0.806331931733861 and parameters: {'h1': 617, 'h2': 414, 'h3': 239, 'dropout_rate': 0.1279849057834933, 'learning_rate': 0.00013220872734030908, 'optimizer': 'Adam', 'batch_size': 128}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:23:50,211] Trial 33 finished with value: 0.8147415285678952 and parameters: {'h1': 667, 'h2': 401, 'h3': 258, 'dropout_rate': 0.04894741024160796, 'learning_rate': 0.0010800847764169835, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:23:53,558] Trial 34 finished with value: 0.8248825129854068 and parameters: {'h1': 639, 'h2': 475, 'h3': 129, 'dropout_rate': 0.24637937583554492, 'learning_rate': 0.0005653943815640525, 'optimizer': 'Adam', 'batch_size': 128}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:23:56,909] Trial 35 finished with value: 0.8214197378184517 and parameters: {'h1': 706, 'h2': 497, 'h3': 124, 'dropout_rate': 0.25654450705508897, 'learning_rate': 0.001730550097202689, 'optimizer': 'Adam', 'batch_size': 160}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:00,255] Trial 36 finished with value: 0.8144941874845412 and parameters: {'h1': 616, 'h2': 475, 'h3': 101, 'dropout_rate': 0.29752060423243565, 'learning_rate': 0.0001638014870431831, 'optimizer': 'Adam', 'batch_size': 128}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:03,539] Trial 37 finished with value: 0.8080633193173387 and parameters: {'h1': 640, 'h2': 430, 'h3': 164, 'dropout_rate': 0.23699285136940088, 'learning_rate': 0.027995643574506072, 'optimizer': 'Adam', 'batch_size': 160}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:06,430] Trial 38 finished with value: 0.8060845906505071 and parameters: {'h1': 662, 'h2': 384, 'h3': 212, 'dropout_rate': 0.20333163995238976, 'learning_rate': 0.004448576678628106, 'optimizer': 'SGD', 'batch_size': 32}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:09,719] Trial 39 finished with value: 0.815483551817957 and parameters: {'h1': 702, 'h2': 370, 'h3': 121, 'dropout_rate': 0.1622444991326865, 'learning_rate': 0.0003820792292656176, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:12,593] Trial 40 finished with value: 0.4620331437051694 and parameters: {'h1': 735, 'h2': 485, 'h3': 141, 'dropout_rate': 0.34368187130693895, 'learning_rate': 2.6697168911354483e-05, 'optimizer': 'SGD', 'batch_size': 128}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:15,898] Trial 41 finished with value: 0.8266139005688845 and parameters: {'h1': 643, 'h2': 468, 'h3': 176, 'dropout_rate': 0.11679201963236821, 'learning_rate': 0.0006335291181972026, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:19,169] Trial 42 finished with value: 0.8144941874845412 and parameters: {'h1': 678, 'h2': 469, 'h3': 179, 'dropout_rate': 0.11223473036343533, 'learning_rate': 0.0014420930008307536, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:22,826] Trial 43 finished with value: 0.8162255750680188 and parameters: {'h1': 645, 'h2': 449, 'h3': 150, 'dropout_rate': 0.15112757945933675, 'learning_rate': 9.314024783206195e-05, 'optimizer': 'Adam', 'batch_size': 128}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:26,760] Trial 44 finished with value: 0.8256245362354687 and parameters: {'h1': 620, 'h2': 336, 'h3': 314, 'dropout_rate': 0.38525683480282813, 'learning_rate': 0.000539073589234116, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:30,469] Trial 45 finished with value: 0.5572594607964383 and parameters: {'h1': 619, 'h2': 330, 'h3': 326, 'dropout_rate': 0.38220962962527233, 'learning_rate': 0.0006073642636848444, 'optimizer': 'SGD', 'batch_size': 64}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:34,526] Trial 46 finished with value: 0.8253771951521147 and parameters: {'h1': 649, 'h2': 305, 'h3': 370, 'dropout_rate': 0.24228577260788267, 'learning_rate': 0.00029176174909865434, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:37,803] Trial 47 finished with value: 0.8231511254019293 and parameters: {'h1': 653, 'h2': 307, 'h3': 410, 'dropout_rate': 0.3767657074262516, 'learning_rate': 0.0002529618047495684, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:40,702] Trial 48 finished with value: 0.7764036606480337 and parameters: {'h1': 667, 'h2': 318, 'h3': 378, 'dropout_rate': 0.4854339532338728, 'learning_rate': 0.0024727278288203206, 'optimizer': 'SGD', 'batch_size': 64}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:43,973] Trial 49 finished with value: 0.824140489735345 and parameters: {'h1': 646, 'h2': 351, 'h3': 343, 'dropout_rate': 0.19241689353978625, 'learning_rate': 0.0003198555213934669, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:47,264] Trial 50 finished with value: 0.8122681177343557 and parameters: {'h1': 630, 'h2': 301, 'h3': 366, 'dropout_rate': 0.2693565092234567, 'learning_rate': 0.007257294794325125, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:50,553] Trial 51 finished with value: 0.8189463269849122 and parameters: {'h1': 637, 'h2': 326, 'h3': 316, 'dropout_rate': 0.23806944707640793, 'learning_rate': 0.001107753526897556, 'optimizer': 'Adam', 'batch_size': 128}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:53,829] Trial 52 finished with value: 0.8191936680682661 and parameters: {'h1': 624, 'h2': 314, 'h3': 394, 'dropout_rate': 0.2496607950266906, 'learning_rate': 0.0004871224504769057, 'optimizer': 'Adam', 'batch_size': 128}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:24:57,106] Trial 53 finished with value: 0.824140489735345 and parameters: {'h1': 659, 'h2': 375, 'h3': 285, 'dropout_rate': 0.2950208710560264, 'learning_rate': 0.00021203416033165192, 'optimizer': 'Adam', 'batch_size': 256}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:25:00,342] Trial 54 finished with value: 0.8169675983180806 and parameters: {'h1': 646, 'h2': 349, 'h3': 263, 'dropout_rate': 0.22631424078848034, 'learning_rate': 0.000781896510511496, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:25:03,623] Trial 55 finished with value: 0.8209250556517438 and parameters: {'h1': 634, 'h2': 338, 'h3': 427, 'dropout_rate': 0.4193397775382792, 'learning_rate': 0.0013349875104659151, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:25:06,897] Trial 56 finished with value: 0.8248825129854068 and parameters: {'h1': 615, 'h2': 484, 'h3': 334, 'dropout_rate': 0.19809935039001253, 'learning_rate': 0.0003401156138118549, 'optimizer': 'Adam', 'batch_size': 192}. Best is trial 26 with value: 0.8271085827355924.\n",
      "[I 2024-03-02 08:25:10,182] Trial 57 finished with value: 0.8276032649023003 and parameters: {'h1': 623, 'h2': 419, 'h3': 303, 'dropout_rate': 0.32277908143661677, 'learning_rate': 0.00019206425089517306, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 57 with value: 0.8276032649023003.\n",
      "[I 2024-03-02 08:25:13,468] Trial 58 finished with value: 0.8186989859015582 and parameters: {'h1': 625, 'h2': 420, 'h3': 308, 'dropout_rate': 0.36943445112296625, 'learning_rate': 0.00014842780306598905, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 57 with value: 0.8276032649023003.\n",
      "[I 2024-03-02 08:25:16,342] Trial 59 finished with value: 0.5572594607964383 and parameters: {'h1': 771, 'h2': 405, 'h3': 296, 'dropout_rate': 0.41195578329593185, 'learning_rate': 8.225733582470463e-05, 'optimizer': 'SGD', 'batch_size': 64}. Best is trial 57 with value: 0.8276032649023003.\n",
      "[I 2024-03-02 08:25:19,630] Trial 60 finished with value: 0.824387830818699 and parameters: {'h1': 612, 'h2': 394, 'h3': 272, 'dropout_rate': 0.4522782340688182, 'learning_rate': 0.0001983627011896286, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 57 with value: 0.8276032649023003.\n",
      "[I 2024-03-02 08:25:22,955] Trial 61 finished with value: 0.8152362107346031 and parameters: {'h1': 650, 'h2': 414, 'h3': 353, 'dropout_rate': 0.3275094762008346, 'learning_rate': 0.0005531843786515971, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 57 with value: 0.8276032649023003.\n",
      "[I 2024-03-02 08:25:26,266] Trial 62 finished with value: 0.8159782339846648 and parameters: {'h1': 639, 'h2': 424, 'h3': 227, 'dropout_rate': 0.18046437270180402, 'learning_rate': 0.0002833579496934962, 'optimizer': 'Adam', 'batch_size': 160}. Best is trial 57 with value: 0.8276032649023003.\n",
      "[I 2024-03-02 08:25:29,525] Trial 63 finished with value: 0.8209250556517438 and parameters: {'h1': 622, 'h2': 465, 'h3': 255, 'dropout_rate': 0.2797658162739856, 'learning_rate': 0.0007273454911734292, 'optimizer': 'Adam', 'batch_size': 128}. Best is trial 57 with value: 0.8276032649023003.\n",
      "[I 2024-03-02 08:25:32,794] Trial 64 finished with value: 0.8100420479841701 and parameters: {'h1': 633, 'h2': 461, 'h3': 206, 'dropout_rate': 0.2272026118585513, 'learning_rate': 0.00041033984307756833, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 57 with value: 0.8276032649023003.\n",
      "[I 2024-03-02 08:25:36,078] Trial 65 finished with value: 0.7937175364828098 and parameters: {'h1': 660, 'h2': 435, 'h3': 183, 'dropout_rate': 0.31893982990806985, 'learning_rate': 0.0144820932022546, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 57 with value: 0.8276032649023003.\n",
      "[I 2024-03-02 08:25:39,348] Trial 66 finished with value: 0.815483551817957 and parameters: {'h1': 652, 'h2': 445, 'h3': 246, 'dropout_rate': 0.3539195122181733, 'learning_rate': 0.002501180954741082, 'optimizer': 'Adam', 'batch_size': 128}. Best is trial 57 with value: 0.8276032649023003.\n",
      "[I 2024-03-02 08:25:42,677] Trial 67 finished with value: 0.82883997031907 and parameters: {'h1': 606, 'h2': 394, 'h3': 457, 'dropout_rate': 0.29517552895821375, 'learning_rate': 0.000986501344091632, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 67 with value: 0.82883997031907.\n",
      "[I 2024-03-02 08:25:45,935] Trial 68 finished with value: 0.8201830324016819 and parameters: {'h1': 608, 'h2': 391, 'h3': 480, 'dropout_rate': 0.2916117629516646, 'learning_rate': 0.000865741828430184, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 67 with value: 0.82883997031907.\n",
      "[I 2024-03-02 08:25:49,232] Trial 69 finished with value: 0.7996537224833045 and parameters: {'h1': 600, 'h2': 372, 'h3': 465, 'dropout_rate': 0.39380890852092587, 'learning_rate': 0.0034144882929056718, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 67 with value: 0.82883997031907.\n",
      "[I 2024-03-02 08:25:52,510] Trial 70 finished with value: 0.8271085827355924 and parameters: {'h1': 627, 'h2': 401, 'h3': 445, 'dropout_rate': 0.30777125891990625, 'learning_rate': 0.00018452868329322844, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 67 with value: 0.82883997031907.\n",
      "[I 2024-03-02 08:25:55,804] Trial 71 finished with value: 0.8177096215681424 and parameters: {'h1': 627, 'h2': 403, 'h3': 453, 'dropout_rate': 0.3139197696882107, 'learning_rate': 0.0001647634536638872, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 67 with value: 0.82883997031907.\n",
      "[I 2024-03-02 08:25:59,037] Trial 72 finished with value: 0.8021271333168439 and parameters: {'h1': 609, 'h2': 381, 'h3': 419, 'dropout_rate': 0.34608487737331095, 'learning_rate': 0.00010855553983746825, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 67 with value: 0.82883997031907.\n",
      "[I 2024-03-02 08:26:02,314] Trial 73 finished with value: 0.8206777145683898 and parameters: {'h1': 618, 'h2': 362, 'h3': 499, 'dropout_rate': 0.26969339582169755, 'learning_rate': 7.700372875372672e-05, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 67 with value: 0.82883997031907.\n",
      "[I 2024-03-02 08:26:05,616] Trial 74 finished with value: 0.8295819935691319 and parameters: {'h1': 643, 'h2': 409, 'h3': 469, 'dropout_rate': 0.3333532600446642, 'learning_rate': 0.00025435001897031634, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:26:08,905] Trial 75 finished with value: 0.8164729161513727 and parameters: {'h1': 633, 'h2': 409, 'h3': 479, 'dropout_rate': 0.33448275308144704, 'learning_rate': 0.000189706645472929, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:26:12,183] Trial 76 finished with value: 0.8216670789018056 and parameters: {'h1': 612, 'h2': 418, 'h3': 434, 'dropout_rate': 0.35764829436029316, 'learning_rate': 3.884040977978003e-05, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:26:15,563] Trial 77 finished with value: 0.8058372495671531 and parameters: {'h1': 605, 'h2': 397, 'h3': 457, 'dropout_rate': 0.30655842287054863, 'learning_rate': 0.0011163057742499735, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:26:18,861] Trial 78 finished with value: 0.8293346524857779 and parameters: {'h1': 622, 'h2': 411, 'h3': 474, 'dropout_rate': 0.4047122466679907, 'learning_rate': 0.00012688018501126754, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:26:21,743] Trial 79 finished with value: 0.5572594607964383 and parameters: {'h1': 643, 'h2': 414, 'h3': 485, 'dropout_rate': 0.031173151586327386, 'learning_rate': 0.00011279621558618811, 'optimizer': 'SGD', 'batch_size': 64}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:26:25,095] Trial 80 finished with value: 0.8186989859015582 and parameters: {'h1': 630, 'h2': 384, 'h3': 473, 'dropout_rate': 0.40247843514953735, 'learning_rate': 6.805025540989796e-05, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:26:28,371] Trial 81 finished with value: 0.8189463269849122 and parameters: {'h1': 622, 'h2': 406, 'h3': 455, 'dropout_rate': 0.43968021440224897, 'learning_rate': 0.0002468284206998291, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:26:31,653] Trial 82 finished with value: 0.8090526836507544 and parameters: {'h1': 620, 'h2': 431, 'h3': 445, 'dropout_rate': 0.3652024567760067, 'learning_rate': 0.00014464012139665488, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:26:34,927] Trial 83 finished with value: 0.8253771951521147 and parameters: {'h1': 613, 'h2': 400, 'h3': 492, 'dropout_rate': 0.33260446479086225, 'learning_rate': 4.743433184246258e-05, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:26:38,198] Trial 84 finished with value: 0.819935691318328 and parameters: {'h1': 642, 'h2': 423, 'h3': 397, 'dropout_rate': 0.39192222872281945, 'learning_rate': 0.00042949960535896794, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:26:41,514] Trial 85 finished with value: 0.8231511254019293 and parameters: {'h1': 637, 'h2': 410, 'h3': 464, 'dropout_rate': 0.14631260686147893, 'learning_rate': 0.0018619280129163374, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:26:44,754] Trial 86 finished with value: 0.8083106604006925 and parameters: {'h1': 626, 'h2': 389, 'h3': 216, 'dropout_rate': 0.2886978418273496, 'learning_rate': 0.006135387702108919, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:26:48,023] Trial 87 finished with value: 0.8246351719020529 and parameters: {'h1': 730, 'h2': 437, 'h3': 277, 'dropout_rate': 0.30289036116082374, 'learning_rate': 0.00035488427105633425, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:26:51,318] Trial 88 finished with value: 0.8011377689834281 and parameters: {'h1': 604, 'h2': 428, 'h3': 446, 'dropout_rate': 0.26184457363732366, 'learning_rate': 0.0005685530951115054, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:26:54,574] Trial 89 finished with value: 0.7991590403165966 and parameters: {'h1': 655, 'h2': 417, 'h3': 434, 'dropout_rate': 0.4285576550654448, 'learning_rate': 0.034797139785499816, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:26:57,451] Trial 90 finished with value: 0.6819193668068266 and parameters: {'h1': 629, 'h2': 378, 'h3': 170, 'dropout_rate': 0.3229949347607896, 'learning_rate': 0.0013696655790224489, 'optimizer': 'SGD', 'batch_size': 32}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:27:00,715] Trial 91 finished with value: 0.8167202572347267 and parameters: {'h1': 618, 'h2': 354, 'h3': 304, 'dropout_rate': 0.21095860639848707, 'learning_rate': 0.000312328476995272, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:27:03,993] Trial 92 finished with value: 0.8224091021518675 and parameters: {'h1': 649, 'h2': 335, 'h3': 324, 'dropout_rate': 0.23835583320130369, 'learning_rate': 0.00024827887534234017, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:27:07,281] Trial 93 finished with value: 0.8110314123175859 and parameters: {'h1': 634, 'h2': 397, 'h3': 373, 'dropout_rate': 0.11454929586672018, 'learning_rate': 0.0002042477652227449, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:27:10,549] Trial 94 finished with value: 0.8251298540687608 and parameters: {'h1': 676, 'h2': 322, 'h3': 294, 'dropout_rate': 0.28156494144648603, 'learning_rate': 0.00016879048679713734, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:27:13,811] Trial 95 finished with value: 0.8186989859015582 and parameters: {'h1': 667, 'h2': 366, 'h3': 406, 'dropout_rate': 0.17028194923402323, 'learning_rate': 0.0001287481251862047, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:27:17,117] Trial 96 finished with value: 0.8100420479841701 and parameters: {'h1': 644, 'h2': 309, 'h3': 351, 'dropout_rate': 0.1577905617798082, 'learning_rate': 0.00046158379067233826, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:27:20,420] Trial 97 finished with value: 0.8219144199851596 and parameters: {'h1': 690, 'h2': 409, 'h3': 316, 'dropout_rate': 0.2586505154390678, 'learning_rate': 0.0006962699347434302, 'optimizer': 'Adam', 'batch_size': 32}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:27:23,685] Trial 98 finished with value: 0.8219144199851596 and parameters: {'h1': 664, 'h2': 423, 'h3': 469, 'dropout_rate': 0.3424084933385886, 'learning_rate': 9.057542162532324e-05, 'optimizer': 'Adam', 'batch_size': 96}. Best is trial 74 with value: 0.8295819935691319.\n",
      "[I 2024-03-02 08:27:27,007] Trial 99 finished with value: 0.824140489735345 and parameters: {'h1': 623, 'h2': 302, 'h3': 190, 'dropout_rate': 0.37697218738485927, 'learning_rate': 0.0002943078303779943, 'optimizer': 'Adam', 'batch_size': 64}. Best is trial 74 with value: 0.8295819935691319.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'h1': 643, 'h2': 409, 'h3': 469, 'dropout_rate': 0.3333532600446642, 'learning_rate': 0.00025435001897031634, 'optimizer': 'Adam', 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "# from optuna import create_study, CmaEsSampler\n",
    "# from optuna.samplers import CmaEsSampler  # 确保导入了 CmaEsSampler\n",
    "import optuna\n",
    "\n",
    "# 创建Optuna研究对象\n",
    "study = optuna.create_study(direction='maximize')\n",
    "# sampler = CmaEsSampler(warn_independent_sampling=False)\n",
    "# study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "\n",
    "# 运行优化\n",
    "study.optimize(optimize, n_trials=100)\n",
    "\n",
    "# 输出最佳超参数\n",
    "print(f'Best parameters found: {study.best_trial.params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da8c3aa",
   "metadata": {},
   "source": [
    "### 保留训练的最优模型的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eba80489-4839-4ee1-8c7e-78fac10d9de5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T07:55:47.057924Z",
     "iopub.status.busy": "2024-03-02T07:55:47.057441Z",
     "iopub.status.idle": "2024-03-02T07:55:47.063563Z",
     "shell.execute_reply": "2024-03-02T07:55:47.062841Z",
     "shell.execute_reply.started": "2024-03-02T07:55:47.057876Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score found: 0.8360128617363344\n"
     ]
    }
   ],
   "source": [
    "# 获取最佳超参数\n",
    "best_params = study.best_trial.params\n",
    "# 获取最佳分数\n",
    "best_score = study.best_trial.value\n",
    "# 输出最佳分数\n",
    "print(f'Best score found: {best_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac7ac2d9-034b-4d3c-8c1e-120fd443a2e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-02T07:56:45.835795Z",
     "iopub.status.busy": "2024-03-02T07:56:45.835328Z",
     "iopub.status.idle": "2024-03-02T07:56:45.845514Z",
     "shell.execute_reply": "2024-03-02T07:56:45.845083Z",
     "shell.execute_reply.started": "2024-03-02T07:56:45.835748Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "best_params = study.best_trial.params\n",
    "with open('best_params_h3_836.json', 'w') as f:\n",
    "    json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44436fe-7b68-462d-bafc-fab83ceb1c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1362b4b6",
   "metadata": {},
   "source": [
    "## 用最优模型参数给出最优模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0d0f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_sizes, output_size,dropout_rate=0.0, learning_rate=0.01, optimizer='adam', batch_size=64):\n",
    "        super(MLP, self).__init__()\n",
    "        # 初始化权重\n",
    "        self.initializer = nn.init.kaiming_normal_\n",
    "        # 设置优化器\n",
    "        if optimizer == 'adam':\n",
    "            self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        elif optimizer == 'sgd':\n",
    "            self.optimizer = optim.SGD(self.parameters(), lr=learning_rate)\n",
    "        # 设置批量大小\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # 第一个隐藏层\n",
    "        layers = [nn.Linear(input_size, hidden_layer_sizes[0])]     \n",
    "        # 添加ReLU激活函数\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        # 添加更多的隐藏层和批归一化层\n",
    "        for i in range(1, len(hidden_layer_sizes)):\n",
    "            layers.extend([\n",
    "                nn.Linear(hidden_layer_sizes[i-1], hidden_layer_sizes[i]),\n",
    "                nn.BatchNorm1d(hidden_layer_sizes[i]),\n",
    "                nn.ReLU()\n",
    "            ])\n",
    "        \n",
    "        # 最后一个隐藏层到输出层\n",
    "        layers.append(nn.Linear(hidden_layer_sizes[-1], output_size))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                self.initializer(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43b5c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个MLP模型实例\n",
    "input_size = 768  # 输入特征维度\n",
    "hidden_layer_sizes = [188, 158, 79]  # 假设有3个隐藏层，分别有188, 158, 79个神经元\n",
    "output_size = 2  # 假设是2分类问题\n",
    "dropout_rate = 0.08290526156007141\n",
    "learning_rate = 0.00020148404515308536\n",
    "optimizer =\"Adam\"\n",
    "batch_size = 96\n",
    "model = MLP(input_size, hidden_layer_sizes, output_size, dropout_rate, learning_rate, optimizer, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d00b0c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.4561, Val Loss: 0.4161, Accuracy: 81.68%\n",
      "Epoch 2/20, Loss: 0.3819, Val Loss: 0.3924, Accuracy: 82.20%\n",
      "Epoch 3/20, Loss: 0.3489, Val Loss: 0.3964, Accuracy: 82.10%\n",
      "Epoch 4/20, Loss: 0.3209, Val Loss: 0.3936, Accuracy: 81.79%\n",
      "Epoch 5/20, Loss: 0.2910, Val Loss: 0.4147, Accuracy: 80.72%\n",
      "Epoch 6/20, Loss: 0.2613, Val Loss: 0.4094, Accuracy: 82.20%\n",
      "Epoch 7/20, Loss: 0.2276, Val Loss: 0.4456, Accuracy: 80.20%\n",
      "Epoch 8/20, Loss: 0.1987, Val Loss: 0.4298, Accuracy: 82.33%\n",
      "Epoch 9/20, Loss: 0.1789, Val Loss: 0.5008, Accuracy: 80.85%\n",
      "Epoch 10/20, Loss: 0.1546, Val Loss: 0.4803, Accuracy: 81.76%\n",
      "Epoch 11/20, Loss: 0.1305, Val Loss: 0.5097, Accuracy: 82.72%\n",
      "Epoch 12/20, Loss: 0.1030, Val Loss: 0.5611, Accuracy: 82.25%\n",
      "Epoch 13/20, Loss: 0.0936, Val Loss: 0.5631, Accuracy: 81.08%\n",
      "Epoch 14/20, Loss: 0.0711, Val Loss: 0.6040, Accuracy: 81.39%\n",
      "Epoch 15/20, Loss: 0.0766, Val Loss: 0.6652, Accuracy: 79.86%\n",
      "Epoch 16/20, Loss: 0.0680, Val Loss: 0.6141, Accuracy: 82.07%\n",
      "Epoch 17/20, Loss: 0.0685, Val Loss: 0.7059, Accuracy: 80.43%\n",
      "Epoch 18/20, Loss: 0.0826, Val Loss: 0.6393, Accuracy: 82.49%\n",
      "Epoch 19/20, Loss: 0.0563, Val Loss: 0.6553, Accuracy: 81.19%\n",
      "Epoch 20/20, Loss: 0.0393, Val Loss: 0.6867, Accuracy: 81.63%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 假设您已经有了模型、数据加载器和损失函数\n",
    "# model = MLP(input_size, hidden_layer_sizes, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 训练模型\n",
    "accuracies = []\n",
    "for epoch in range(20):\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:  # 假设train_loader是训练数据的DataLoader\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        outputs = model(inputs)  # 前向传播\n",
    "        loss = criterion(outputs, labels)  # 计算损失\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 参数更新\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # 验证模型\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # 在验证时不计算梯度\n",
    "        for inputs, labels in val_loader:  # 假设val_loader是验证数据的DataLoader\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    # 打印统计信息\n",
    "    print(f'Epoch {epoch+1}/{20}, Loss: {running_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')\n",
    "    accuracies.append(100 * correct / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4252ec64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.54696851418161"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 算平均准确率\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "average_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f78967",
   "metadata": {},
   "source": [
    "### 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a47083cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在训练结束后保存模型\n",
    "torch.save(model.state_dict(), 'best_model_state_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0ee4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68345a95",
   "metadata": {},
   "source": [
    "### 测试保存的模型是否可用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa6a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型实例（确保模型架构与训练时相同）\n",
    "# 创建一个MLP模型实例\n",
    "input_size = 768  # 输入特征维度\n",
    "hidden_layer_sizes = [188, 158, 79]  # 假设有3个隐藏层，分别有188, 158, 79个神经元\n",
    "output_size = 2  # 假设是2分类问题\n",
    "dropout_rate = 0.08290526156007141\n",
    "learning_rate = 0.00020148404515308536\n",
    "optimizer =\"Adam\"\n",
    "batch_size = 96\n",
    "model1 = MLP(input_size, hidden_layer_sizes, output_size, dropout_rate, learning_rate, optimizer, batch_size)\n",
    "\n",
    "# 加载保存的模型参数\n",
    "model1.load_state_dict(torch.load('./bert/best_model_state_dict.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6501dc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Val Loss: 0.2228, Accuracy: 81.90%\n"
     ]
    }
   ],
   "source": [
    "# 验证模型\n",
    "model1.eval()  # 设置模型为评估模式\n",
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # 在验证时不计算梯度\n",
    "    for inputs, labels in val_loader1:  # 假设val_loader是验证数据的DataLoader\n",
    "        outputs = model1(inputs)\n",
    "        val_loss += criterion(outputs, labels).item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# 打印统计信息\n",
    "print(f' Val Loss: {val_loss/len(val_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
